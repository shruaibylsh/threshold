{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfa6425",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the .npy files are stored\n",
    "DATA_FOLDER = r\"C:\\Users\\shrua\\OneDrive\\Desktop\\threshold project\\threshold\\data\\processed\"\n",
    "class IsovistDataset(Dataset):\n",
    "    def __init__(self, data_folder):\n",
    "        self.data = []\n",
    "        self.file_names = []\n",
    "\n",
    "        for f in os.listdir(data_folder):\n",
    "            if f.endswith('.npy'):\n",
    "                path = os.path.join(data_folder, f)\n",
    "                array = np.load(path)  # Load ONCE\n",
    "                self.data.append(torch.tensor(array, dtype=torch.float32))\n",
    "                self.file_names.append(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.file_names[idx]\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = IsovistDataset(DATA_FOLDER)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ac853",
   "metadata": {},
   "source": [
    "## frame encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3639c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP to encode each isovist (2048 → 128)\n",
    "class IsovistFrameEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IsovistFrameEncoder, self).__init__()\n",
    "        \n",
    "        # Define a simple MLP architecture\n",
    "        self.fc1 = nn.Linear(2048, 512)  # First layer (2048 → 512)\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.fc2 = nn.Linear(512, 128)  # Second layer (512 → 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for frame encoding\n",
    "        x: tensor of shape [batch_size, 2048]\n",
    "        \"\"\"\n",
    "        x = self.relu(self.fc1(x))  # First layer\n",
    "        x = self.fc2(x)  # Second layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalTransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, num_heads=4, ff_dim=256, num_layers=3):\n",
    "        \"\"\"\n",
    "        A Transformer Encoder that processes the 7-frame sequence.\n",
    "        \"\"\"\n",
    "        super(TemporalTransformerEncoder, self).__init__()\n",
    "        \n",
    "        # Define transformer encoder layer with batch_first=True\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,  # Each frame has 128 features\n",
    "            nhead=num_heads,  # Number of attention heads\n",
    "            dim_feedforward=ff_dim,  # Feed-forward layer size\n",
    "            batch_first=True  # Ensure batch-first format (batch_size, seq_len, input_dim)\n",
    "        )\n",
    "        \n",
    "        # Wrap encoder layers in a TransformerEncoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, \n",
    "            num_layers=num_layers  # Number of transformer layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the temporal transformer\n",
    "        x: tensor of shape [batch_size, seq_len, input_dim]\n",
    "        \"\"\"\n",
    "        return self.transformer_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec296fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatioTemporalModel, self).__init__()\n",
    "        self.frame_encoder = IsovistFrameEncoder()  # Frame encoding layer\n",
    "        self.temporal_encoder = TemporalTransformerEncoder(input_dim=128)  # Transformer encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, 2048]\n",
    "        \n",
    "        # Step 1: Encode each frame (2048 → 128)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        x_reshaped = x.view(-1, 2048)                # [B×7, 2048]\n",
    "        encoded = self.frame_encoder(x_reshaped)     # [B×7, 128]\n",
    "        frame_embeddings = encoded.view(batch_size, seq_len, 128)  # [B, 7, 128]\n",
    "        \n",
    "        # Step 2: Apply Transformer to sequence of frame embeddings (7, 128) → (7, 128)\n",
    "        transformer_output = self.temporal_encoder(frame_embeddings)  # shape: [batch_size, 7, 128]\n",
    "        \n",
    "        # Step 3: Aggregate over the sequence (mean pooling)\n",
    "        aggregated = transformer_output.mean(dim=1)  # shape: [batch_size, 128]\n",
    "        \n",
    "        return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NT_XentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(NT_XentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        \"\"\"\n",
    "        Compute the normalized temperature-scaled cross-entropy loss.\n",
    "        \"\"\"\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        # Compute similarity\n",
    "        similarity_matrix = torch.matmul(z1, z2.T) / self.temperature\n",
    "        \n",
    "        # Create labels: 0,1 for positive pair (same batch)\n",
    "        labels = torch.arange(batch_size).to(z1.device)\n",
    "        \n",
    "        # Cross entropy loss\n",
    "        loss = nn.CrossEntropyLoss()(similarity_matrix, labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11788a4f",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories for saving models\n",
    "CHECKPOINT_FOLDER = r\"C:\\Users\\shrua\\OneDrive\\Desktop\\threshold project\\threshold\\data\\checkpoints\"\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "TEMPERATURE = 0.1  # for SimCLR\n",
    "\n",
    "# Function for visualizing loss over training epochs\n",
    "def plot_loss(training_losses):\n",
    "    plt.plot(training_losses, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# SimCLR loss function (NT-Xent Loss)\n",
    "class NT_XentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(NT_XentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        \"\"\"\n",
    "        Compute the normalized temperature-scaled cross-entropy loss (NT-Xent Loss).\n",
    "        \"\"\"\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        # Compute cosine similarity between all pairs\n",
    "        similarity_matrix = torch.matmul(z1, z2.T) / self.temperature  # similarity = cos(theta)\n",
    "        \n",
    "        # Create labels: 0,1 for positive pair (same batch)\n",
    "        labels = torch.arange(batch_size).to(z1.device)\n",
    "        \n",
    "        # Cross entropy loss\n",
    "        loss = nn.CrossEntropyLoss()(similarity_matrix, labels)\n",
    "        return loss\n",
    "\n",
    "# Initialize your model\n",
    "model = SpatioTemporalModel()  # Assuming you already have SpatioTemporalModel defined earlier\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = NT_XentLoss(temperature=TEMPERATURE)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "def train_one_epoch(model, data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(data_loader)\n",
    "    \n",
    "    for batch_data, _ in data_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        \n",
    "        # Step 1: Forward pass through the model\n",
    "        z1 = model(batch_data)  # Get the latent vector for first view (e.g., augmented version 1)\n",
    "        \n",
    "        # Apply augmentation (e.g., jitter, scaling) to generate a second view for contrastive learning\n",
    "        augmented_data = batch_data + 0.01 * torch.randn_like(batch_data)\n",
    "        z2 = model(augmented_data)  # Get the latent vector for second view (augmented version 2)\n",
    "\n",
    "\n",
    "        # Step 2: Compute the contrastive loss (SimCLR)\n",
    "        loss = loss_fn(z1, z2)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / total_batches\n",
    "    return epoch_loss\n",
    "\n",
    "# Lists to track loss for visualization\n",
    "training_losses = []\n",
    "\n",
    "# Training loop\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, data_loader, optimizer, loss_fn, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Optional validation phase\n",
    "    # val_loss = validate(model, val_loader, device)  # If you have a validation set\n",
    "    # print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save the model checkpoint if it improves\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_FOLDER, f\"model_epoch_{epoch + 1}.pt\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model checkpoint at epoch {epoch + 1}\")\n",
    "    \n",
    "    # Track loss for visualization\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "# Plot the loss curve\n",
    "# plot_loss(training_losses)\n",
    "\n",
    "print(training_losses)\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92170635",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract latent vectors from the dataset\n",
    "def extract_latent_vectors(model, data_loader, device):\n",
    "    model.eval()\n",
    "    latent_vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, file_names in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            \n",
    "            # Get latent vector for each sample\n",
    "            latent_vector = model(batch_data)  # shape: [batch_size, 128]\n",
    "            latent_vectors.append(latent_vector.cpu().numpy())\n",
    "            \n",
    "            # Optional: store file names for labeling clusters\n",
    "            labels.extend(file_names)\n",
    "    \n",
    "    return np.concatenate(latent_vectors, axis=0), labels\n",
    "\n",
    "# Extract latent vectors (this will be done after model training)\n",
    "latent_vectors, labels = extract_latent_vectors(model, data_loader, device)\n",
    "print(\"Latent vectors shape:\", latent_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17563dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE for dimensionality reduction to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latent_vectors_2d = tsne.fit_transform(latent_vectors)\n",
    "\n",
    "# Plot the t-SNE projection\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(latent_vectors_2d[:, 0], latent_vectors_2d[:, 1], c='blue', s=5, alpha=0.5)\n",
    "plt.title(\"t-SNE Visualization of Latent Space\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b01ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans clustering to the latent vectors\n",
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "labels_kmeans = kmeans.fit_predict(latent_vectors)\n",
    "\n",
    "# Plot the t-SNE projection with K-means cluster coloring\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(latent_vectors_2d[labels_kmeans == i, 0], latent_vectors_2d[labels_kmeans == i, 1], label=f'Cluster {i + 1}', s=5, alpha=0.7)\n",
    "\n",
    "plt.title(f\"K-Means Clustering (k={num_clusters})\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ace66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract group from filename\n",
    "def extract_group_from_filename(filename):\n",
    "    match = re.match(r\"t(\\d+)-\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Returns the group number (1 to 8)\n",
    "    return None  # Return None if no match found\n",
    "\n",
    "# Extract true labels (group numbers) from file names in dataset\n",
    "true_labels = [extract_group_from_filename(f) for f in dataset.file_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract latent vectors from the dataset\n",
    "def extract_latent_vectors(model, data_loader, device):\n",
    "    model.eval()\n",
    "    latent_vectors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            \n",
    "            # Get latent vector for each sample\n",
    "            latent_vector = model(batch_data)  # shape: [batch_size, 128]\n",
    "            latent_vectors.append(latent_vector.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(latent_vectors, axis=0)\n",
    "\n",
    "# Extract latent vectors (after model training)\n",
    "latent_vectors = extract_latent_vectors(model, data_loader, device)\n",
    "print(\"Latent vectors shape:\", latent_vectors.shape)\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latent_vectors_2d = tsne.fit_transform(latent_vectors)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "num_clusters = 8  # Based on the group labels\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "predicted_labels = kmeans.fit_predict(latent_vectors)\n",
    "\n",
    "# Plot t-SNE with KMeans clusters (predicted) and true labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot predicted KMeans clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(num_clusters):  # 8 clusters based on \"t1\" to \"t8\"\n",
    "    plt.scatter(latent_vectors_2d[predicted_labels == i, 0], latent_vectors_2d[predicted_labels == i, 1], label=f'Cluster {i+1}', s=5, alpha=0.7)\n",
    "plt.title(\"Predicted Clusters (K-Means)\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot true labels (from filenames)\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(1, 9):  # 8 true groups (t1 to t8)\n",
    "    plt.scatter(latent_vectors_2d[np.array(true_labels) == i, 0], latent_vectors_2d[np.array(true_labels) == i, 1], label=f't{i}', s=5, alpha=0.7)\n",
    "plt.title(\"True Groups (From Filenames)\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
