{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d88879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from load_data import create_dataloaders, CFG\n",
    "from timesformer_min import TimeSformerEncoder\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same loaders; here we *use* labels\n",
    "dl_train, dl_val, dl_test = create_dataloaders(CFG, batch_size=128, num_workers=4)\n",
    "for loader in (dl_train, dl_val, dl_test):\n",
    "    if hasattr(loader, \"pin_memory\"):\n",
    "        loader.pin_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e720744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrain from: C:\\Users\\shrua\\OneDrive\\Desktop\\threshold project\\threshold\\models\\timesformer_ssl_50.pth \n",
      "(strict=False)\n"
     ]
    }
   ],
   "source": [
    "class ThresholdClassifier(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        # infer feature dim\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(2, 7, 1, 32, 64, device=next(encoder.parameters()).device)\n",
    "            feat_dim = self.encoder(dummy).shape[-1]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(feat_dim),\n",
    "            nn.Linear(feat_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):            # x: [B,T,1,32,64]\n",
    "        h = self.encoder(x)          # [B,D]\n",
    "        logits = self.classifier(h)  # [B,8]\n",
    "        return logits\n",
    "\n",
    "# Build encoder with same sizes you used in Step 2\n",
    "encoder = TimeSformerEncoder(\n",
    "    in_ch=1, embed_dim=384, depth=6, num_heads=6,\n",
    "    mlp_ratio=4.0, drop=0.1, attn_drop=0.0,\n",
    "    patch=(8,8), T=7, H=32, W=64\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained SimCLR weights\n",
    "ckpt = r\"C:\\Users\\shrua\\OneDrive\\Desktop\\threshold project\\threshold\\models\\timesformer_ssl_50.pth\"\n",
    "state = torch.load(ckpt, map_location=device)\n",
    "missing, unexpected = encoder.load_state_dict(state, strict=False), None\n",
    "print(\"Loaded pretrain from:\", ckpt, \"\\n(strict=False)\")\n",
    "\n",
    "model = ThresholdClassifier(encoder).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8597e4",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09fde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    # confusion counts for macro-F1\n",
    "    num_classes = 8\n",
    "    TP = torch.zeros(num_classes, dtype=torch.long, device=device)\n",
    "    FP = torch.zeros(num_classes, dtype=torch.long, device=device)\n",
    "    FN = torch.zeros(num_classes, dtype=torch.long, device=device)\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"video\"].to(device)           # [B,T,1,32,64]\n",
    "        y = batch[\"label\"].to(device)           # [B]\n",
    "        logits = model(x)                       # [B,8]\n",
    "        pred = logits.argmax(dim=1)             # [B]\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "\n",
    "        # per-class stats\n",
    "        for c in range(num_classes):\n",
    "            TP[c] += ((pred == c) & (y == c)).sum()\n",
    "            FP[c] += ((pred == c) & (y != c)).sum()\n",
    "            FN[c] += ((pred != c) & (y == c)).sum()\n",
    "\n",
    "    acc = correct / max(1, total)\n",
    "    # macro-F1\n",
    "    precision = TP.float() / torch.clamp(TP + FP, min=1)\n",
    "    recall    = TP.float() / torch.clamp(TP + FN, min=1)\n",
    "    f1_per_c  = 2 * precision * recall / torch.clamp(precision + recall, min=1e-8)\n",
    "    macro_f1  = f1_per_c.mean().item()\n",
    "\n",
    "    return acc, macro_f1, f1_per_c.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7922186",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3a2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear] epoch 01  loss 2.0824  val_acc 0.150  val_F1 0.055\n",
      "[Linear] epoch 02  loss 2.0662  val_acc 0.237  val_F1 0.096\n",
      "[Linear] epoch 03  loss 2.0631  val_acc 0.263  val_F1 0.146\n",
      "[Linear] epoch 04  loss 2.0636  val_acc 0.237  val_F1 0.128\n",
      "[Linear] epoch 05  loss 2.0612  val_acc 0.237  val_F1 0.112\n",
      "[Linear] epoch 06  loss 2.0590  val_acc 0.237  val_F1 0.112\n",
      "[Linear] epoch 07  loss 2.0607  val_acc 0.225  val_F1 0.090\n",
      "[Linear] epoch 08  loss 2.0610  val_acc 0.225  val_F1 0.090\n",
      "[Linear] epoch 09  loss 2.0610  val_acc 0.200  val_F1 0.095\n",
      "[Linear] epoch 10  loss 2.0620  val_acc 0.125  val_F1 0.028\n",
      "[Linear] epoch 11  loss 2.0647  val_acc 0.250  val_F1 0.100\n",
      "[Linear] epoch 12  loss 2.0634  val_acc 0.200  val_F1 0.079\n",
      "[Linear] epoch 13  loss 2.0628  val_acc 0.225  val_F1 0.093\n",
      "[Linear] epoch 14  loss 2.0591  val_acc 0.100  val_F1 0.033\n",
      "[Linear] epoch 15  loss 2.0573  val_acc 0.125  val_F1 0.062\n",
      "[Linear] epoch 16  loss 2.0585  val_acc 0.125  val_F1 0.062\n",
      "[Linear] epoch 17  loss 2.0585  val_acc 0.237  val_F1 0.168\n",
      "[Linear] epoch 18  loss 2.0589  val_acc 0.225  val_F1 0.090\n",
      "[Linear] epoch 19  loss 2.0589  val_acc 0.237  val_F1 0.111\n",
      "[Linear] epoch 20  loss 2.0585  val_acc 0.125  val_F1 0.028\n",
      "[Linear] epoch 21  loss 2.0620  val_acc 0.125  val_F1 0.028\n",
      "[Linear] epoch 22  loss 2.0581  val_acc 0.250  val_F1 0.188\n",
      "[Linear] epoch 23  loss 2.0577  val_acc 0.225  val_F1 0.128\n",
      "[Linear] epoch 24  loss 2.0578  val_acc 0.300  val_F1 0.198\n",
      "[Linear] epoch 25  loss 2.0571  val_acc 0.225  val_F1 0.111\n",
      "[Linear] epoch 26  loss 2.0553  val_acc 0.225  val_F1 0.111\n",
      "[Linear] epoch 27  loss 2.0563  val_acc 0.250  val_F1 0.136\n",
      "[Linear] epoch 28  loss 2.0569  val_acc 0.325  val_F1 0.248\n",
      "[Linear] epoch 29  loss 2.0572  val_acc 0.188  val_F1 0.077\n",
      "[Linear] epoch 30  loss 2.0557  val_acc 0.138  val_F1 0.057\n",
      "[Finetune] epoch 01  loss 2.1937  val_acc 0.125  val_F1 0.028\n",
      "saved\n",
      "[Finetune] epoch 02  loss 2.1654  val_acc 0.125  val_F1 0.028\n",
      "[Finetune] epoch 03  loss 2.0198  val_acc 0.250  val_F1 0.165\n",
      "saved\n",
      "[Finetune] epoch 04  loss 1.8854  val_acc 0.300  val_F1 0.176\n",
      "saved\n",
      "[Finetune] epoch 05  loss 1.6324  val_acc 0.338  val_F1 0.267\n",
      "saved\n",
      "[Finetune] epoch 06  loss 1.4430  val_acc 0.212  val_F1 0.151\n",
      "[Finetune] epoch 07  loss 1.4226  val_acc 0.475  val_F1 0.419\n",
      "saved\n",
      "[Finetune] epoch 08  loss 1.2728  val_acc 0.450  val_F1 0.400\n",
      "[Finetune] epoch 09  loss 1.1655  val_acc 0.512  val_F1 0.437\n",
      "saved\n",
      "[Finetune] epoch 10  loss 1.1101  val_acc 0.600  val_F1 0.540\n",
      "saved\n",
      "[Finetune] epoch 11  loss 0.9701  val_acc 0.562  val_F1 0.511\n",
      "[Finetune] epoch 12  loss 0.9203  val_acc 0.688  val_F1 0.628\n",
      "saved\n",
      "[Finetune] epoch 13  loss 0.8535  val_acc 0.575  val_F1 0.499\n",
      "[Finetune] epoch 14  loss 0.8165  val_acc 0.700  val_F1 0.649\n",
      "saved\n",
      "[Finetune] epoch 15  loss 0.7684  val_acc 0.625  val_F1 0.570\n",
      "[Finetune] epoch 16  loss 0.7240  val_acc 0.738  val_F1 0.678\n",
      "saved\n",
      "[Finetune] epoch 17  loss 0.7068  val_acc 0.738  val_F1 0.675\n",
      "[Finetune] epoch 18  loss 0.7105  val_acc 0.750  val_F1 0.696\n",
      "saved\n",
      "[Finetune] epoch 19  loss 0.6802  val_acc 0.750  val_F1 0.698\n",
      "saved\n",
      "[Finetune] epoch 20  loss 0.7155  val_acc 0.750  val_F1 0.702\n",
      "saved\n",
      "[Finetune] epoch 21  loss 0.7048  val_acc 0.750  val_F1 0.702\n",
      "[Finetune] epoch 22  loss 0.7032  val_acc 0.750  val_F1 0.709\n",
      "saved\n",
      "[Finetune] epoch 23  loss 0.7085  val_acc 0.762  val_F1 0.735\n",
      "saved\n",
      "[Finetune] epoch 24  loss 0.7035  val_acc 0.775  val_F1 0.743\n",
      "saved\n",
      "[Finetune] epoch 25  loss 0.6618  val_acc 0.800  val_F1 0.777\n",
      "saved\n",
      "[Finetune] epoch 26  loss 0.6574  val_acc 0.800  val_F1 0.777\n",
      "[Finetune] epoch 27  loss 0.6289  val_acc 0.775  val_F1 0.726\n",
      "[Finetune] epoch 28  loss 0.5857  val_acc 0.800  val_F1 0.762\n",
      "[Finetune] epoch 29  loss 0.5074  val_acc 0.675  val_F1 0.642\n",
      "[Finetune] epoch 30  loss 0.4769  val_acc 0.850  val_F1 0.817\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "use_amp = (device == \"cuda\")\n",
    "\n",
    "def train_step(model, batch, opt, scaler):\n",
    "    model.train()\n",
    "    x = batch[\"video\"].to(device)\n",
    "    y = batch[\"label\"].to(device)\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(opt)\n",
    "    scaler.update()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# --- optimizers & schedulers ---\n",
    "# Start with linear probe (freeze encoder), then unfreeze\n",
    "for p in model.encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "opt = torch.optim.AdamW(model.classifier.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=5)\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "# --- linear probe epochs ---\n",
    "lin_epochs = 30\n",
    "hist = {\"train_loss\": [], \"val_acc\": [], \"val_f1\": []}\n",
    "\n",
    "for ep in range(1, lin_epochs+1):\n",
    "    running = 0.0\n",
    "    for batch in dl_train:\n",
    "        running += train_step(model, batch, opt, scaler)\n",
    "    sched.step()\n",
    "\n",
    "    acc, mf1, _ = evaluate(model, dl_val)\n",
    "    hist[\"train_loss\"].append(running / max(1, len(dl_train)))\n",
    "    hist[\"val_acc\"].append(acc)\n",
    "    hist[\"val_f1\"].append(mf1)\n",
    "    print(f\"[Linear] epoch {ep:02d}  loss {hist['train_loss'][-1]:.4f}  val_acc {acc:.3f}  val_F1 {mf1:.3f}\")\n",
    "\n",
    "# --- unfreeze encoder: full fineâ€‘tune ---\n",
    "for p in model.encoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n",
    "\n",
    "best_val = -1.0\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "ft_epochs = 30\n",
    "for ep in range(1, ft_epochs+1):\n",
    "    running = 0.0\n",
    "    for batch in dl_train:\n",
    "        running += train_step(model, batch, opt, scaler)\n",
    "    sched.step()\n",
    "\n",
    "    acc, mf1, _ = evaluate(model, dl_val)\n",
    "    tr_loss = running / max(1, len(dl_train))\n",
    "    print(f\"[Finetune] epoch {ep:02d}  loss {tr_loss:.4f}  val_acc {acc:.3f}  val_F1 {mf1:.3f}\")\n",
    "\n",
    "    if mf1 > best_val:\n",
    "        best_val = mf1\n",
    "        torch.save(model.state_dict(), r\"C:\\Users\\shrua\\OneDrive\\Desktop\\threshold project\\threshold\\models\\timesformer_cls.pth\")\n",
    "        print(\"saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
